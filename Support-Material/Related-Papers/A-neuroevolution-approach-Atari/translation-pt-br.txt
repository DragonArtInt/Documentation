Este artigo aborda o desafio de aprender a jogar diferentes jogos de vídeo game com pouco conhecimento específico. Especificamente, introduz uma abordagem de neuroevolução aos jogos do Atari 2600. Quatro algoritmos de neuroevolução foram combinados com três diferentes representações de estado e avaliados em um conjunto de 61 jogos do Atari. Os agentes neuroevolutivos representam diferentes pontos ao longo do espectro de sofisticação algorítmica, incluindo evolução de peso em redes neurais topologicamente fixas (neuroevolução convencional), estratégia de evolução da adaptação da matriz de covariância (CMA-ES), neuroevolução de topologias aumentadas (NEAT), e codificação de rede indireta ( HyperNEAT). As representações de estado incluem uma objeto de representação da tela do jogo, os pixels brutos da tela do jogo e o ruído semeado (uma linha de base comparativa). Os resultados indicam que os métodos de codificação direta funcionam melhor em representações de estado compacto, enquanto os métodos de codificação indireta (isto é, HyperNEAT) permitem dimensionamento para representações dimensionais mais altas (isto é, a tela bruta do jogo). Abordagens anteriores baseadas na aprendizagem de diferenças temporais (TD) tiveram dificuldade em lidar com os grandes espaços de estado e os gradientes de recompensa escassos frequentemente encontrados nos jogos da Atari. A neuroevolução melhora esses problemas e as políticas evoluídas alcançam resultados de ponta, superando até as altas pontuações humanas em três jogos. Esses resultados sugerem que a neuroevolução é uma abordagem promissora para o videogame em geral (GVGP).

Um grande desafio para a IA é desenvolver agentes que possam aprender a executar muitas tarefas diferentes. Para este fim, este artigo descreve uma classe de agentes capazes de aprender a jogar um grande número de jogos do Atari 2600 com pouco conhecimento de domínio específico. Os jogos Atari 2600 representam um meio termo entre jogos de tabuleiro clássicos e videogames mais recentes e graficamente intensivos. O Atari 2600 inclui muitos jogos diferentes que abrangem vários gêneros, incluindo jogos de tabuleiro como Xadrez e Damas, jogos de ação e aventura como o Pitfall, jogos de tiro como Space Invaders e Centipede, jogos rudimentares em 3-D como

Battlezone e clássicos de arcade como Frogger e Pac-Man. Alguns exemplos de jogos são mostrados na Fig. 1. Do ponto de vista do praticante da IAA, os jogos da Atari são semelhantes aos jogos de tabuleiro tradicionais, em que um agente da AI pode se beneficiar do planejamento inteligente e de uma sólida compreensão da dinâmica do jogo. Eles também são semelhantes aos videogames modernos, pois oferecem oportunidades para que um agente processe e aprenda com a ação que está ocorrendo na tela do jogo. Apesar da variabilidade da dinâmica do jogo, todos os jogos da Atari compartilham uma interface padrão projetada para humanos. O estado do jogo é transmitido ao jogador através de uma tela de jogo 2-D e, em resposta, o jogador controla os elementos do jogo manipulando um joystick e pressionando um único botão. A diversidade de jogos, a aplicabilidade das técnicas fundamentais de IA e a interface padronizada fazem do Atari 2600 uma plataforma atraente para o desenvolvimento de um agente geral de videogame (GVGP).

Neste artigo, quatro algoritmos de neuroevolução usando três diferentes representações de estado são aplicados a 61 jogos da Atari. Este trabalho baseia-se no HyperNEAT-GGP, um agente de jogos Atari baseado em HyperNEAT [18] que demonstrou aprender em dois diferentes jogos da Atari: Freeway e Asterix. O HyperNEAT-GGP exigia conhecimento específico do jogo para inicializar a rede neural associada e selecionar ações. Essas restrições são removidas neste artigo, estendendo o HyperNEAT-GGP para muitos outros jogos da Atari. Além disso, esta abordagem é avaliada no contexto de uma classe mais ampla de algoritmos de aprendizagem neuroevolucionária com a intenção de investigar o desempenho algorítmico como um fator de representação de estado e sofisticação algorítmica. Especificamente, as seguintes questões são abordadas: 1) Como o desempenho muda como um fator de sofisticação do algoritmo? 2) Como o desempenho da neuroevolução escala em função da representação do estado? 3) Como os algoritmos evolutivos apresentados neste trabalho se comparam a benchmarks anteriores, incluindo algoritmos de aprendizagem de diferença temporal (TD), algoritmos de planejamento e especialistas humanos?

O artigo está organizado da seguinte forma. A Seção II descreve os méritos do Atari 2600 como uma plataforma de pesquisa, e a Seção III revisa trabalhos relacionados nesta área. Em seguida, a Seção IV abrange os quatro diferentes algoritmos de neuroevolução, enquanto a Seção V descreve as representações de estado usadas por esses algoritmos. Finalmente, as Seções VI a VIII descrevem as especificidades da interface desses algoritmos com o domínio Atari e os experimentos em execução, e as Seções IX e X apresentam os resultados e suas análises, em particular, respondendo às questões acima.